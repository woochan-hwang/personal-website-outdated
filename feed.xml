<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://woochan-hwang.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://woochan-hwang.github.io/" rel="alternate" type="text/html" /><updated>2019-02-15T11:41:05+00:00</updated><id>https://woochan-hwang.github.io/feed.xml</id><title type="html">Woochan Hwang</title><subtitle>Medical Student with passion in ML</subtitle><entry><title type="html">Machine Learning in Psychiatry</title><link href="https://woochan-hwang.github.io/Machine-learning-in-Psychiatry/" rel="alternate" type="text/html" title="Machine Learning in Psychiatry" /><published>2019-02-08T00:00:00+00:00</published><updated>2019-02-08T00:00:00+00:00</updated><id>https://woochan-hwang.github.io/Machine-learning-in-Psychiatry</id><content type="html" xml:base="https://woochan-hwang.github.io/Machine-learning-in-Psychiatry/">&lt;p&gt;Last week I attended yet another hackathon - the &lt;a href=&quot;http://medtechsuperconnector.com/&quot;&gt;MedTech SuperConnector challenge&lt;/a&gt;. The topic of the weekend was mental health, and coincidently it happened at the end of my 6 week psychiatric attachment. Instead of talking about our idea, which is I feel is not developed enough for a post, I wanted to write about some fundamental difficulties in taking a data driven approach for psychiatric conditions. I will give a brief introduction to how such conditions are defined clinically, discuss the current approaches and end with my opinion on how we should approach this field.&lt;/p&gt;

&lt;h2 id=&quot;clinical-classification&quot;&gt;Clinical classification&lt;/h2&gt;

&lt;p&gt;There are two main classification guidelines used by clinicians for mental disorders: ICD-10 (11th revision released in 2018) endorsed by the World Health Organisation and DSM-IV endorsed by the American Psychiatric Association. For the purpose of this post, I will use the &lt;a href=&quot;https://www.who.int/classifications/icd/en/bluebook.pdf&quot;&gt;ICD-10 guideline&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The ICD-10 groups mental disorders in the following large categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Organic disorders - mainly dementia&lt;/li&gt;
  &lt;li&gt;Substance abuse&lt;/li&gt;
  &lt;li&gt;Schizophrenia and delusional disorders&lt;/li&gt;
  &lt;li&gt;Mood disorders&lt;/li&gt;
  &lt;li&gt;Neurotic and stress related disorders&lt;/li&gt;
  &lt;li&gt;Behavioural, personality, developmental disorders&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have rephrased and combined the last few categories for the non-clinical readers. Of these, I will discuss mood disorders as they currently seem to be one of the most popular topics for machine learning applications.&lt;/p&gt;

&lt;h3 id=&quot;mood-disorders---depression&quot;&gt;Mood Disorders - depression&lt;/h3&gt;

&lt;p&gt;This category includes mania related conditions as well. However, due to its relative frequency, most recent works have focused on depression. Here is how depression is described:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In typical depressive episodes of all three varieties described below (mild, moderate, and severe) the individual usually suffers from depressed mood, loss of interest and enjoyment, and reduced energy leading to increased fatiguability and diminished activity. Marked tiredness after only slight effort is common. [F32 Depressive episode, ICD-10]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In clinical practice, we often use the PHQ-9 questionnaire, which was developed by Pfizer based on the above description (they cited the APA guidelines but that is irrelevant here). The questionnaire begins with the following question: “Over the last two weeks, how often have you been bothered by any of the following problems?”. The nine problems that follow are “Little interest or pleasure in doing things?”, “Feeling down, depressed, or hopeless?”, and etc. Patients are asked to answer the above questions in one of the four choices (not at all, some days, most days, all days), which is converted to a score of 0 ~ 3 respectively.&lt;/p&gt;

&lt;p&gt;As subjective as the above method may seem, a &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/11556941&quot;&gt;validation study&lt;/a&gt; of the PHQ-9 survey showed that a score &amp;gt;= 10 had a 88% specificity and 88% sensitivity for major depression. So far so good. However, the paper itself states that the positive predictive score for the mild and moderate thresholds drops significantly to 31%. Furthermore, the original study does not include how sensitive the scores are to the change of patient state. The only two studies&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0165032703001988&quot;&gt;1&lt;/a&gt;,&lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2894391/&quot;&gt;2&lt;/a&gt; that I found to have attempted this both conclude that a better trial is required to assess the hypothesis. Considering the inherent subjectiveness of not only the questionnaire but also the definition of a depressive disorder, any quantitative analysis will likely have a huge uncertainty.&lt;/p&gt;

&lt;h2 id=&quot;uncertainty---why-does-it-matter&quot;&gt;Uncertainty - why does it matter?&lt;/h2&gt;

&lt;p&gt;We need to understand the character of the uncertainty in this situation. In &lt;a href=&quot;http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf&quot;&gt;Yarin Gal’s PhD thesis&lt;/a&gt;, he explains the possible sources of uncertainty in machine learning as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;noisy data (our observed labels might be noisy, for example as a result of measurement imprecision, leading to aleatoric uncertainty)&lt;/li&gt;
  &lt;li&gt;uncertainty in model parameters that best explain the observed data (a large number of possible models might be able to explain a given dataset, in which case we might be uncertain which model parameters to choose to predict with)&lt;/li&gt;
  &lt;li&gt;structure uncertainty (what model structure should we use? how do we specify our model to extrapolate / interpolate well?).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These were written in the context of machine learning, however it is closely related to our discussion if you view the PHQ-9 as the first layer of a neural network model that extracts a certain set of features. The above can be rephrased.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;noisy data (depression severity is very subjective and easily influenced by environmental factors)&lt;/li&gt;
  &lt;li&gt;model parameters (which of the PHQ-9 survey questions are most predictive?)&lt;/li&gt;
  &lt;li&gt;structure uncertainty (is the PHQ-9 survey deep &amp;amp; wide enough?)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Understanding the source of uncertainty matters as it will change how we respond to them.&lt;/p&gt;

&lt;h2 id=&quot;what-do-we-do&quot;&gt;What do we do?&lt;/h2&gt;

&lt;p&gt;There are several approaches to what we can do to address each uncertainty. The first source, which is inherently caused by the lack of a quantitative definition of depression, can be considered using a probabilistic modelling approach to some degree. Fundamentally, we will need to gather more information from the subject about the spatiotemporal environment to rule out unrelated affects. Perhaps considering the approach of causal inference researchers may be worth a try.&lt;/p&gt;

&lt;p&gt;The other two sources of uncertainty are to do with the PHQ-9 survey - a hand crafted feature extraction model. The development of deep neural networks have made such attempts obsolete in many domains and I believe depression is no exception. We need to look at the raw data, which in this case is the audio record of a consultation where the clinician assesses the descriptive criteria of depression. Although there are works attempting to predict depression from vocal prosody, many of them are limited by the fact that their labels are based on the PHQ-9 (or equivalent surveys) scores, which is the very source of uncertainty that we want to address. Attempts to predict depression from facial expressions are also interesting but problematic from the uncertainty perspective. As much as I agree with the potential benefit of this, we need to be careful as facial expression are likely to be ‘associated with’ depression but may not have a direct causal relationship with the clinical definition of depression.&lt;/p&gt;</content><author><name></name></author><category term="Machine Learning" /><category term="Psychiatry" /><category term="Mood Disorders" /><category term="Uncertainty" /><summary type="html">subjectivity in depression scoring</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://woochan-hwang.github.io/images/MTSC.jpeg" /></entry><entry><title type="html">At the End of 2018</title><link href="https://woochan-hwang.github.io/review-of-2018/" rel="alternate" type="text/html" title="At the End of 2018" /><published>2018-12-31T00:00:00+00:00</published><updated>2018-12-31T00:00:00+00:00</updated><id>https://woochan-hwang.github.io/review-of-2018</id><content type="html" xml:base="https://woochan-hwang.github.io/review-of-2018/">&lt;p&gt;On the last day of 2018, I’m sitting in my living room trying to finish up my first website. After many commits and banging my head on the table, I ended up with this beautiful Jekyll theme, which was mostly based on the work of &lt;a href=&quot;https://github.com/srekoble&quot;&gt;Vangelis Tzortzis&lt;/a&gt; (&lt;a href=&quot;http://vangeltzo.com/&quot;&gt;vangeltzo.com&lt;/a&gt;). Though it turned out to be slightly more challenging than expected, I’m pretty content with the result.&lt;/p&gt;

&lt;p&gt;As the first post of the new website, I think a review of the main projects I worked on in 2018 is well suited given the time of the year.&lt;/p&gt;

&lt;h2 id=&quot;projects&quot;&gt;Projects&lt;/h2&gt;

&lt;h3 id=&quot;denoising-ecgs-using-accelerometer-signals-and-denoising-autoencoders&quot;&gt;Denoising ECGs using accelerometer signals and Denoising Autoencoders&lt;/h3&gt;

&lt;p&gt;This was a year long group project that was part of my intercalated BSc degree in Biomedical Engineering. We had a fantastic group of people working together to build a prototype of an Armband that could collect clean electrocardiogram (ECG) signals. The main motivation behind this work was that real time continuous ECG monitoring is limited by the high level of EMG noise (which arise from the underlying muscles) that can’t be filtered in the traditional way.&lt;/p&gt;

&lt;p&gt;Over the year we tested different materials and positioning for the electrodes, designed a PCB, and programmed an algorithm for integrating the accelerometer and electrode signals to produce a clean ECG even during active movement. My main contribution was leading the modelling of the neural network that would work as a robust filter against EMG. To achieve this, I used the PyTorch framework to implement neural networks with LSTM and Convolutional components. There was quite a learning curve as my previous python experience was minimal and I had to figure out how to train models on AWS and the university computing cluster. At the end of the day, I created a Convolutional Denoising Autoencoder structure that outperformed the state of the art performance in ECG denoising.&lt;/p&gt;

&lt;h3 id=&quot;rest-decreasing-the-labeling-burden-by-integrating-reinforcement-learning-to-self-training-for-pulmonary-nodule-segmentation-in-chest-x-rays&quot;&gt;ReST: Decreasing the Labeling Burden by Integrating Reinforcement Learning to Self Training for Pulmonary Nodule Segmentation in Chest X-rays&lt;/h3&gt;

&lt;p&gt;The second half of the year was invested in finishing up this project which came to life while drinking beer in Chicago while attending RSNA (Radiology Society of North America). At the 2017 RSNA, there was so much interest in AI that some people jokingly called the conference RSNAI. What I found frustrating was that every company that had a showcase at the conference seemed to be working on the exact same problem of finding nodules in Lung CTs. Practically, it was understandable as there was a well established dataset and a potential market. However, the true potential of clinical decision support systems is, in my opinion, when the use case currently lacks doctors. Long story short, I came to the conclusion that the accessibility to quality labels was one of the key bottlenecks in widespread application of supervised learning models in medical imaging and decided to work on semi-supervised learning methods.&lt;/p&gt;

&lt;p&gt;In the ReST paper, which was presented at the ML4H workshop at NeurIPS, we explore the self training method, a form of semi-supervised learning, to address the labeling burden. The main objectives of the paper were:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reduce the labeling burden for supervised segmentation models in Medical Imaging&lt;/li&gt;
  &lt;li&gt;Must be easily incorporated into existing models&lt;/li&gt;
  &lt;li&gt;Provide stable convergence to a clinically valid hypothesis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This work was only possible because of the great support of my co-author Sejin Park and VUNO who kindly sponsored my trip to NeurIPS. I am still very passionate about semi-supervised learning methods and will post a quick review on the current trends soon.&lt;/p&gt;

&lt;h2 id=&quot;travelling&quot;&gt;Travelling&lt;/h2&gt;

&lt;p&gt;Thought it would be nice to leave a record of the places I travelled in 2018 to make it more like a proper end of year review. I started the New Year in Paris with my family. Then I flew over to Lisbon in Feb for a few days to enjoy the sun and meet a few friends. Went back to South Korea over the summer holidays. Visited Montreal for NeurIPS and then Copenhagen in the following week with a group of friends.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paris, France&lt;/li&gt;
  &lt;li&gt;Lisbon, Portugal&lt;/li&gt;
  &lt;li&gt;Seoul, South Korea&lt;/li&gt;
  &lt;li&gt;Montreal, Canada&lt;/li&gt;
  &lt;li&gt;Copenhagen, Denmark&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;inspiration&quot;&gt;Inspiration&lt;/h2&gt;

&lt;h3 id=&quot;world-models-by-david-ha-and-jürgen-schmidhuber&quot;&gt;World Models by David Ha and Jürgen Schmidhuber&lt;/h3&gt;

&lt;p&gt;I just want to end this post with a brief discussion about a paper I found quite inspirational. The World Models paper mainly focuses on the idea that we learn and make decisions based on an abstract representation of the world. This representation is not just an abstraction in the spatial sense but also the temporal which means that it will actively be predicting the future sensory input.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To handle the vast amount of information that flows through our daily lives, our brain learns an abstract representation of both spatial and temporal aspects of this information. We are able to observe a scene and remember an abstract description thereof. Evidence also suggests that what we perceive at any given moment is governed by our brain’s prediction of the future based on our internal model. [Ha, 2018]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This concept has a rather long history, especially in the realm of Neurobiology, but is yet to be integrated in the computational frameworks. I think the World Models approach and HTM approach of Numenta are the closest to making this happen. Along with the trend of Meta Learning / Continual Learning which also has many overlapping ideas, I am very excited for all the new developments that will happen in the new year.&lt;/p&gt;</content><author><name></name></author><category term="Review" /><category term="EndofYear" /><summary type="html">First commit: Project Review</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://woochan-hwang.github.io/images/endofyear.jpeg" /></entry></feed>